/*
Robert Wright
COMP360 
Project 1
2/23/25

*/


#include <iostream>
#include <vector>
#include <string>
#include <regex>
#include <stdexcept>

// Token types
enum class TokenType {
    KEYWORD, IDENTIFIER, OPERATOR, DELIMITER, NUMBER, WHITESPACE, UNKNOWN
};

// Token class to store token type and value
struct Token {
    TokenType type;
    std::string value;

    Token(TokenType type, const std::string& value) : type(type), value(value) {}

    friend std::ostream& operator<<(std::ostream& os, const Token& token) {
        os << "(" << static_cast<int>(token.type) << ", " << token.value << ")";
        return os;
    }
};

// Lexical analyzer
std::vector<Token> lexicalAnalyzer(const std::string& sourceCode) {
    std::vector<Token> tokens;
    std::vector<std::pair<TokenType, std::string>> tokenPatterns = {
        {TokenType::KEYWORD, "(float|while)"},
        {TokenType::IDENTIFIER, "[a-zA-Z_][a-zA-Z0-9_]*"},
        {TokenType::OPERATOR, ">=|[+\\-*/=]"}, // Added >= as a single token
        {TokenType::DELIMITER, "[();{}]"},
        {TokenType::NUMBER, "\\d+"},
        {TokenType::WHITESPACE, "\\s+"},
        {TokenType::UNKNOWN, "."}
    };

    std::string remainingCode = sourceCode;
    std::smatch match;

    while (!remainingCode.empty()) {
        bool matched = false;
        for (const auto& pattern : tokenPatterns) {
            std::regex regex(pattern.second);
            if (std::regex_search(remainingCode, match, regex, std::regex_constants::match_continuous)) {
                std::string value = match.str(0);
                if (pattern.first != TokenType::WHITESPACE) {
                    tokens.push_back(Token(pattern.first, value));
                }
                remainingCode = match.suffix().str();
                matched = true;
                break;
            }
        }
        if (!matched) {
            throw std::runtime_error("Unknown token: " + remainingCode.substr(0, 1));
        }
    }

    return tokens;
}

// Recursive-descent parser
class Parser {
private:
    std::vector<Token> tokens;
    size_t currentTokenIndex;

    Token currentToken() {
        if (currentTokenIndex < tokens.size()) {
            return tokens[currentTokenIndex];
        }
        return {TokenType::UNKNOWN, ""};
    }

    void match(TokenType expectedType, const std::string& expectedValue = "") {
        Token token = currentToken();
        if (token.type == expectedType && (expectedValue.empty() || token.value == expectedValue)) {
            currentTokenIndex++;
        } else {
            throw std::runtime_error("Expected " + std::to_string(static_cast<int>(expectedType)) + 
                                    " " + expectedValue + ", but found " + token.value);
        }
    }

    void program() {
        match(TokenType::KEYWORD, "float");
        ident();
        match(TokenType::DELIMITER, "(");
        match(TokenType::DELIMITER, ")");
        match(TokenType::DELIMITER, "{");
        declares();
        stmts();
        loop();
        stmts();
        match(TokenType::DELIMITER, "}");
    }

    void declares() {
        while (currentToken().value == "float") {
            match(TokenType::KEYWORD, "float");
            ident();
            match(TokenType::DELIMITER, ";");
        }
    }

    void stmts() {
        while (currentToken().type == TokenType::IDENTIFIER) {
            assign();
            match(TokenType::DELIMITER, ";");
        }
    }

    void assign() {
        ident();
        match(TokenType::OPERATOR, "=");
        expr();
    }

    void expr() {
        ident();
        if (currentToken().value == "*" || currentToken().value == "/") {
            match(TokenType::OPERATOR);
            expr();
        }
    }

    void loop() {
        match(TokenType::KEYWORD, "while");
        match(TokenType::DELIMITER, "(");
        ident();
        match(TokenType::OPERATOR, ">="); // Expect a single >= token
        match(TokenType::NUMBER, "10");
        match(TokenType::DELIMITER, ")");
    }

    void ident() {
        match(TokenType::IDENTIFIER);
    }

public:
    Parser(const std::vector<Token>& tokens) : tokens(tokens), currentTokenIndex(0) {}

    void parse() {
        try {
            program();
            if (currentToken().type != TokenType::UNKNOWN) {
                throw std::runtime_error("Unexpected token at the end of input: " + currentToken().value);
            }
            std::cout << "The Source Code is generated by the BNF grammar" << std::endl;
        } catch (const std::runtime_error& e) {
            std::cout << "The Source Code cannot be generated by the Sample Function defined language, and " 
                      << e.what() << std::endl;
        }
    }
};

// Test the program
void test(const std::string& sourceCode) {
    try {
        std::vector<Token> tokens = lexicalAnalyzer(sourceCode);
        std::cout << "Tokens: ";
        for (const auto& token : tokens) {
            std::cout << token << " ";
        }
        std::cout << std::endl;

        Parser parser(tokens);
        parser.parse();
    } catch (const std::runtime_error& e) {
        std::cout << "Error: " << e.what() << std::endl;
    }
}

int main() {
    // Source Code 1
    std::string sourceCode1 = R"(
        float sample1 (){
            float data;
            float num;
            float diff;
            float n;
            data = data * num / diff;
            while (n >= 10)
                n = n * diff;
        }
    )";

    // Source Code 2
    std::string sourceCode2 = R"(
        float mul (float data1, float number ) {
            data1 = data1 * number;
            while (data >= const)
        }
    )";

    // Run the tests
    std::cout << "Testing Source Code 1:" << std::endl;
    test(sourceCode1);

    std::cout << "\nTesting Source Code 2:" << std::endl;
    test(sourceCode2);

    return 0;
}